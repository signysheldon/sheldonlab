{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Topic Modeling Analysis Reference Methods\n","\n","The following contains reference methods used for the LDA topic model analysis in the submitted paper:\n","\n","### CONTENT ANALYSIS, AGING AND AUTOBIOGRAPHICAL MEMORY Differences in the Content and Coherence of Autobiographical Memories Between Younger and Older Adults: Insights from Text Analysis \n","\n","\n","-----------------"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This document presents the primary steps in building the latent dirichlet topic model using in the associated analysis."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Processing\n","\n","Transcripts loaded into a pandas dataframe, tagged with additional information from each respondent.\n","cleaning involved \n","- removing stop words\n","- removal of specific non-verbal entries (dashes, etc)\n","- lemmatization of input tokens and associated POS tagging\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The data file after cleaning was called  **lda_df**\n","\n","and contained the followig columns:\n","\n","- subject_id - id of the subject giving narration\n","- gender\n","- age - numeric age\n","- group - grouped age\n","- stage - stage on which the transcript was narrativing (ie, childhood memory, adult memory etc)\n","- transcript_id - the id for this transcript (unique for subject_id X stage)\n","\n","- token - each row has one token from that transcript\n","- lemma - the lemmatization of the token\n","- pos - associated part of speech tag (granular category)\n","- pos_type - broader grouping of the pos (ie, noun, verb, etc)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model Building"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1638179380110,"user":{"displayName":"Wenlan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03844243280765622293"},"user_tz":300},"id":"BvbmKdEuHwNZ","outputId":"760a2cbf-1403-4bc8-914b-ee09e22a622e"},"outputs":[],"source":["# IMPORT STATEMENTS\n","import pandas as pd\n","import os\n","import tqdm\n","import string \n","import re\n","import numpy as np\n","from pprint import pprint\n","\n","# Gensim\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","\n","# nltk\n","import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk import sent_tokenize\n","from nltk import word_tokenize\n","\n","# lemmatizer \n","from nltk.stem import WordNetLemmatizer \n","nltk.download('wordnet')\n","lemmatizer = WordNetLemmatizer()\n","\n","# spacy's lemmatizer was used\n","import spacy\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TT6y0XG9mWHn"},"source":["### Method Used For Model Building "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","#### LDA_DF -> Input Documents\n"," Generate Input Documents from lda_df, based on queries over transcripts (eg, age) and lemmas (eg, using POS to select)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7578,"status":"ok","timestamp":1638169000430,"user":{"displayName":"Wenlan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03844243280765622293"},"user_tz":300},"id":"tZN7o5-wTaeN","outputId":"2b52a5d6-5c15-498b-e83c-0a3a74538f2b"},"outputs":[],"source":["def create_input_docs(TRANSCRIPT_QUERY, LEMMA_TOKEN_QUERY,lemma_or_token,lda_df, lda_df_name):\n","\n","  # 1) FILTER BASED ON TRANSCRIPT_QUERY\n","  # make sure the query we give is not empty \n","  if len(TRANSCRIPT_QUERY) > 0:\n","    # create the df \"selected_tokens\"\n","    selected_tokens = lda_df.query(TRANSCRIPT_QUERY).copy(deep=False)\n","  # if no transcript query, just take them all\n","  else:  \n","    selected_tokens = lda_df.copy(deep=False)\n","\n","  # 2) FILTER BASED ON LEMMA_QUERY\n","  selected_tokens = selected_tokens.query(LEMMA_TOKEN_QUERY)\n","\n","  # 3) SET INPUT_DOCS AS: \n","  input_docs = selected_tokens.groupby(\"transcript_id\")[lemma_or_token].apply(lambda x: list(x))\n","\n","  # Checking: \n","  print(\"lda_df_name: \", lda_df_name, \" | TRANSCRIPT_QUERY:\", TRANSCRIPT_QUERY, \" | LEMMA_TOKEN_QUERY:\", LEMMA_TOKEN_QUERY, \" | lemma_or_token:\", lemma_or_token)\n","  print(\"Working with %s docs with a total of %s tokens\"%(len(input_docs), selected_tokens.shape[0]))\n","\n","  return input_docs"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Input Documents --> Corpus\n","Uses input documents to create an associated corpus & dictionary for handling bag of words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_dictionary_and_corpus(input_docs, do_filter, no_below_i, no_above_i):\n","\n","  # 1) create Dictionary\n","  id2word = corpora.Dictionary(input_docs)\n","\n","  # 2) FILTER EXTREME WORDS \n","  if do_filter == True:\n","\n","    id2word.filter_extremes(no_below=no_below_i, no_above=no_above_i)\n","\n","  # 3) map corpus with this dictionary - this uses a BOW model\n","  corpus = [id2word.doc2bow(text) for text in input_docs]\n","\n","  # 4) Term Document Frequency\n","  corpus = [id2word.doc2bow(text) for text in input_docs]\n","\n","  # 5) View\n","  print(corpus[:1])\n","\n","  return id2word, corpus"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Documents + Corpus --> LDA Model\n","Run LDA Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def run_lda_model(corpus, id2word, NUM_TOPICS, output_file):\n","\n","  # 1) rerun lda model with NUM_TOPICS \n","  lda_model = gensim.models.LdaModel(corpus=corpus,\n","                                          id2word=id2word,\n","                                          alpha='auto', \n","                                          eta='auto',\n","                                          num_topics=NUM_TOPICS, \n","                                          random_state=100,\n","                                          chunksize=100,\n","                                          passes=10,\n","                                          per_word_topics=True)\n"," \n","  #per_word_topics (bool) â€“ If True, the model also computes a list of topics, \n","  #sorted in descending order of most likely topics for each word, along with \n","  #their phi values multiplied by the feature length (i.e. word count)\n","  \n","  # 2) print the Keyword in the topics\n","  pprint(lda_model.print_topics())\n","\n","  # 3) open the file and write topics into it\n","  with open(output_file, 'wt') as out:\n","    \n","    pprint(lda_model.print_topics(), stream=out)\n","\n","  # ??? \n","  doc_lda = lda_model[corpus] \n","\n","  return lda_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_topic_scores(lda_model, input_docs):\n","\n","\n","    input_doc_series = pd.Series([list(x.items()) for x in input_docs], index=input_docs.index)\n","    input_doc_topics_df = input_doc_series.explode().reset_index()\n","    input_doc_topics_df.rename(columns={0:\"topic_score\"},inplace=True)\n","\n","    #  Name the topics starting with 1, by default they start with 0.\n","    input_doc_topics_df[\"topic\"] = input_doc_topics_df[\"topic_score\"].map(lambda x: \"topic %s\"%(x[0]+1))  # note, by default first topic is 0 - fix that here by adding 1\n","    input_doc_topics_df[\"value\"] = input_doc_topics_df[\"topic_score\"].map(lambda x: x[1])\n","\n","\n","    input_doc_topics_df.drop(columns='topic_score',inplace=True)\n","\n","    return input_doc_topics_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### LDA Model --> Coherence Score\n","Determining the coherence and perplexity for LDA model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compute_perplexity_and_coherence(lda_model,corpus,input_docs,id2word):\n","\n","\n","  # 2) compute Perplexity\n","  perplexity_score = lda_model.log_perplexity(corpus)\n","  print('\\nPerplexity: ', perplexity_score)  # a measure of how good the model is. lower the better.\n","\n","\n","  # 3) compute Coherence Score\n","  coherence_model_lda = CoherenceModel(model=lda_model, texts=input_docs, dictionary=id2word, coherence='c_v')\n","  coherence_lda = coherence_model_lda.get_coherence()\n","  print('\\nCoherence Score: ', coherence_lda)\n","\n","\n","  return perplexity_score, coherence_lda"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Graph Coherence Scores\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_graph_of_coherence(coherence_values, num_topics_min, num_topics_max, graph_title):\n","\n","  limit=num_topics_max; start=num_topics_min; step=1\n","\n","  x = range(start, limit, step)\n","\n","  plt.plot(x, coherence_values)\n","  plt.title(graph_title)\n","  plt.xlabel(\"Number of topics\")\n","  plt.ylabel(\"Coherence score\")\n","  plt.legend((\"coherence_values\"), loc='best')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPPa0Qk45dF2L4ycB3VK10k","collapsed_sections":["NhDdXduTlt1T","cOLshLPy7QwS","QEHRdr1ByrC3","1dueG4uAAJpn","vDsTzLSGUhPF","FApWlEscmeuV"],"name":"2_filter_dataframe.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
