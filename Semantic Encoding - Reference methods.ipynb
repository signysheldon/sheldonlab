{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Embedding Analysis\n",
        "\n",
        "The following contains reference methods used for the LDA topic model analysis in the submitted paper:\n",
        "\n",
        "### CONTENT ANALYSIS, AGING AND AUTOBIOGRAPHICAL MEMORY Differences in the Content and Coherence of Autobiographical Memories Between Younger and Older Adults: Insights from Text Analysis \n",
        "\n",
        "\n",
        "-----------------"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input Transcript Text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "transcripts_df is a dataframe with the following columns:\n",
        "- subject_id\n",
        "- transcript_id\n",
        "- raw_text - the text of the transcript\n",
        "- stage, which is one of: 'teenage', 'childhood', 'adult', 'earlyadult', 'middleadult',\n",
        "       'lateadult'\n",
        "- agegroup: younger, older\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analytic Methods"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Universal Sentence Encoder\n",
        "And prepare function to calculate internal correlations for a set of text inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# load Google's Universal Setence Encoder\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)\n",
        "\n",
        "\n",
        "def embed(input):\n",
        "  return model(input)\n",
        "\n",
        "\n",
        "def get_embedding_correlations(text_list):\n",
        "  text_embeddings = embed(text_list)\n",
        "  text_embeddings_corr = np.inner(text_embeddings, text_embeddings)\n",
        "  n = text_embeddings_corr.shape[1]\n",
        "  average_other_correlations = (text_embeddings_corr.mean(1)-1./n)*(n/(n-1))\n",
        "  return dict(corr_avg=average_other_correlations.mean(),corr_var=average_other_correlations.var(), num_gt_0p4 = (average_other_correlations>0.4).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prepare Transcript Sliding Window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_split_indexes(x):\n",
        "  index_series = pd.Series([0]+[m.start() for m in re.finditer('[\\., ]', x)] + [len(x)])\n",
        "  return list(index_series.loc[index_series.diff().map(lambda x: pd.isna(x) or x>1)].values)\n",
        "\n",
        "def window_text(x, window_length=15, stride_length=15):\n",
        "  token_split_indexes = get_split_indexes(x)\n",
        "  num_tokens = len(token_split_indexes)\n",
        "  window_texts = []\n",
        "  t1 = 0\n",
        "  t2 = min(num_tokens-1, window_length)\n",
        "  while t2 < num_tokens:\n",
        "    i1 = token_split_indexes[t1]\n",
        "    i2 = token_split_indexes[t2]\n",
        "\n",
        "    window_texts += [x[i1:i2]]\n",
        "    \n",
        "    t1 = t1 + stride_length\n",
        "    t2 = t2 + stride_length\n",
        "  return window_texts\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Internal Similarity For Transcript Sliding Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcripts_df[\"window_texts\"] = transcripts_df.raw_text.map(window_text)\n",
        "transcripts_df[\"num_window_texts\"] = transcripts_df.window_texts.map(len)\n",
        "\n",
        "transcripts_df = transcripts_df.query(\"num_window_texts > 3\")\n",
        "\n",
        "transcripts_df[\"internal_similarity\"] = transcripts_df[\"window_texts\"].map(get_embedding_correlations)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine average internal similarity score per transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcripts_df[\"internal_similarity_mean\"] = transcripts_df[\"internal_similarity\"].map(lambda x: None if not x else x.get(\"corr_avg\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
